{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross validation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "mFRDcqkP_ldg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "df = pd.DataFrame(np.c_[cancer['data'],cancer['target']],columns = np.append(cancer['feature_names'],['target']))\n",
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "0uMQnTlb_lOH",
        "outputId": "2e7be9a5-dbcd-4ad0-982f-d3fca22c7e76"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-51ff972a-0945-4c9a-860e-2f1d06c8ba92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>23.29</td>\n",
              "      <td>26.67</td>\n",
              "      <td>158.90</td>\n",
              "      <td>1685.0</td>\n",
              "      <td>0.11410</td>\n",
              "      <td>0.20840</td>\n",
              "      <td>0.35230</td>\n",
              "      <td>0.16200</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.06229</td>\n",
              "      <td>0.5539</td>\n",
              "      <td>1.5600</td>\n",
              "      <td>4.667</td>\n",
              "      <td>83.16</td>\n",
              "      <td>0.009327</td>\n",
              "      <td>0.05121</td>\n",
              "      <td>0.08958</td>\n",
              "      <td>0.024650</td>\n",
              "      <td>0.02175</td>\n",
              "      <td>0.005195</td>\n",
              "      <td>25.12</td>\n",
              "      <td>32.68</td>\n",
              "      <td>177.00</td>\n",
              "      <td>1986.0</td>\n",
              "      <td>0.1536</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0.78920</td>\n",
              "      <td>0.27330</td>\n",
              "      <td>0.3198</td>\n",
              "      <td>0.08762</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>12.19</td>\n",
              "      <td>13.29</td>\n",
              "      <td>79.08</td>\n",
              "      <td>455.8</td>\n",
              "      <td>0.10660</td>\n",
              "      <td>0.09509</td>\n",
              "      <td>0.02855</td>\n",
              "      <td>0.02882</td>\n",
              "      <td>0.1880</td>\n",
              "      <td>0.06471</td>\n",
              "      <td>0.2005</td>\n",
              "      <td>0.8163</td>\n",
              "      <td>1.973</td>\n",
              "      <td>15.24</td>\n",
              "      <td>0.006773</td>\n",
              "      <td>0.02456</td>\n",
              "      <td>0.01018</td>\n",
              "      <td>0.008094</td>\n",
              "      <td>0.02662</td>\n",
              "      <td>0.004143</td>\n",
              "      <td>13.34</td>\n",
              "      <td>17.81</td>\n",
              "      <td>91.38</td>\n",
              "      <td>545.2</td>\n",
              "      <td>0.1427</td>\n",
              "      <td>0.2585</td>\n",
              "      <td>0.09915</td>\n",
              "      <td>0.08187</td>\n",
              "      <td>0.3469</td>\n",
              "      <td>0.09241</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>27.22</td>\n",
              "      <td>21.87</td>\n",
              "      <td>182.10</td>\n",
              "      <td>2250.0</td>\n",
              "      <td>0.10940</td>\n",
              "      <td>0.19140</td>\n",
              "      <td>0.28710</td>\n",
              "      <td>0.18780</td>\n",
              "      <td>0.1800</td>\n",
              "      <td>0.05770</td>\n",
              "      <td>0.8361</td>\n",
              "      <td>1.4810</td>\n",
              "      <td>5.820</td>\n",
              "      <td>128.70</td>\n",
              "      <td>0.004631</td>\n",
              "      <td>0.02537</td>\n",
              "      <td>0.03109</td>\n",
              "      <td>0.012410</td>\n",
              "      <td>0.01575</td>\n",
              "      <td>0.002747</td>\n",
              "      <td>33.12</td>\n",
              "      <td>32.85</td>\n",
              "      <td>220.80</td>\n",
              "      <td>3216.0</td>\n",
              "      <td>0.1472</td>\n",
              "      <td>0.4034</td>\n",
              "      <td>0.53400</td>\n",
              "      <td>0.26880</td>\n",
              "      <td>0.2856</td>\n",
              "      <td>0.08082</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>13.27</td>\n",
              "      <td>17.02</td>\n",
              "      <td>84.55</td>\n",
              "      <td>546.4</td>\n",
              "      <td>0.08445</td>\n",
              "      <td>0.04994</td>\n",
              "      <td>0.03554</td>\n",
              "      <td>0.02456</td>\n",
              "      <td>0.1496</td>\n",
              "      <td>0.05674</td>\n",
              "      <td>0.2927</td>\n",
              "      <td>0.8907</td>\n",
              "      <td>2.044</td>\n",
              "      <td>24.68</td>\n",
              "      <td>0.006032</td>\n",
              "      <td>0.01104</td>\n",
              "      <td>0.02259</td>\n",
              "      <td>0.009057</td>\n",
              "      <td>0.01482</td>\n",
              "      <td>0.002496</td>\n",
              "      <td>15.14</td>\n",
              "      <td>23.60</td>\n",
              "      <td>98.84</td>\n",
              "      <td>708.8</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.1311</td>\n",
              "      <td>0.17860</td>\n",
              "      <td>0.09678</td>\n",
              "      <td>0.2506</td>\n",
              "      <td>0.07623</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>16.26</td>\n",
              "      <td>21.88</td>\n",
              "      <td>107.50</td>\n",
              "      <td>826.8</td>\n",
              "      <td>0.11650</td>\n",
              "      <td>0.12830</td>\n",
              "      <td>0.17990</td>\n",
              "      <td>0.07981</td>\n",
              "      <td>0.1869</td>\n",
              "      <td>0.06532</td>\n",
              "      <td>0.5706</td>\n",
              "      <td>1.4570</td>\n",
              "      <td>2.961</td>\n",
              "      <td>57.72</td>\n",
              "      <td>0.010560</td>\n",
              "      <td>0.03756</td>\n",
              "      <td>0.05839</td>\n",
              "      <td>0.011860</td>\n",
              "      <td>0.04022</td>\n",
              "      <td>0.006187</td>\n",
              "      <td>17.73</td>\n",
              "      <td>25.21</td>\n",
              "      <td>113.70</td>\n",
              "      <td>975.2</td>\n",
              "      <td>0.1426</td>\n",
              "      <td>0.2116</td>\n",
              "      <td>0.33440</td>\n",
              "      <td>0.10470</td>\n",
              "      <td>0.2736</td>\n",
              "      <td>0.07953</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>14.04</td>\n",
              "      <td>15.98</td>\n",
              "      <td>89.78</td>\n",
              "      <td>611.2</td>\n",
              "      <td>0.08458</td>\n",
              "      <td>0.05895</td>\n",
              "      <td>0.03534</td>\n",
              "      <td>0.02944</td>\n",
              "      <td>0.1714</td>\n",
              "      <td>0.05898</td>\n",
              "      <td>0.3892</td>\n",
              "      <td>1.0460</td>\n",
              "      <td>2.644</td>\n",
              "      <td>32.74</td>\n",
              "      <td>0.007976</td>\n",
              "      <td>0.01295</td>\n",
              "      <td>0.01608</td>\n",
              "      <td>0.009046</td>\n",
              "      <td>0.02005</td>\n",
              "      <td>0.002830</td>\n",
              "      <td>15.66</td>\n",
              "      <td>21.58</td>\n",
              "      <td>101.20</td>\n",
              "      <td>750.0</td>\n",
              "      <td>0.1195</td>\n",
              "      <td>0.1252</td>\n",
              "      <td>0.11170</td>\n",
              "      <td>0.07453</td>\n",
              "      <td>0.2725</td>\n",
              "      <td>0.07234</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>11.74</td>\n",
              "      <td>14.69</td>\n",
              "      <td>76.31</td>\n",
              "      <td>426.0</td>\n",
              "      <td>0.08099</td>\n",
              "      <td>0.09661</td>\n",
              "      <td>0.06726</td>\n",
              "      <td>0.02639</td>\n",
              "      <td>0.1499</td>\n",
              "      <td>0.06758</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.6417</td>\n",
              "      <td>1.345</td>\n",
              "      <td>13.04</td>\n",
              "      <td>0.006982</td>\n",
              "      <td>0.03916</td>\n",
              "      <td>0.04017</td>\n",
              "      <td>0.015280</td>\n",
              "      <td>0.02260</td>\n",
              "      <td>0.006822</td>\n",
              "      <td>12.45</td>\n",
              "      <td>17.60</td>\n",
              "      <td>81.25</td>\n",
              "      <td>473.8</td>\n",
              "      <td>0.1073</td>\n",
              "      <td>0.2793</td>\n",
              "      <td>0.26900</td>\n",
              "      <td>0.10560</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.09879</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>20.59</td>\n",
              "      <td>21.24</td>\n",
              "      <td>137.80</td>\n",
              "      <td>1320.0</td>\n",
              "      <td>0.10850</td>\n",
              "      <td>0.16440</td>\n",
              "      <td>0.21880</td>\n",
              "      <td>0.11210</td>\n",
              "      <td>0.1848</td>\n",
              "      <td>0.06222</td>\n",
              "      <td>0.5904</td>\n",
              "      <td>1.2160</td>\n",
              "      <td>4.206</td>\n",
              "      <td>75.09</td>\n",
              "      <td>0.006666</td>\n",
              "      <td>0.02791</td>\n",
              "      <td>0.04062</td>\n",
              "      <td>0.014790</td>\n",
              "      <td>0.01117</td>\n",
              "      <td>0.003727</td>\n",
              "      <td>23.86</td>\n",
              "      <td>30.76</td>\n",
              "      <td>163.20</td>\n",
              "      <td>1760.0</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.3597</td>\n",
              "      <td>0.51790</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.2480</td>\n",
              "      <td>0.08999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>13.69</td>\n",
              "      <td>16.07</td>\n",
              "      <td>87.84</td>\n",
              "      <td>579.1</td>\n",
              "      <td>0.08302</td>\n",
              "      <td>0.06374</td>\n",
              "      <td>0.02556</td>\n",
              "      <td>0.02031</td>\n",
              "      <td>0.1872</td>\n",
              "      <td>0.05669</td>\n",
              "      <td>0.1705</td>\n",
              "      <td>0.5066</td>\n",
              "      <td>1.372</td>\n",
              "      <td>14.00</td>\n",
              "      <td>0.004230</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.01169</td>\n",
              "      <td>0.006335</td>\n",
              "      <td>0.01943</td>\n",
              "      <td>0.002177</td>\n",
              "      <td>14.84</td>\n",
              "      <td>20.21</td>\n",
              "      <td>99.16</td>\n",
              "      <td>670.6</td>\n",
              "      <td>0.1105</td>\n",
              "      <td>0.2096</td>\n",
              "      <td>0.13460</td>\n",
              "      <td>0.06987</td>\n",
              "      <td>0.3323</td>\n",
              "      <td>0.07701</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>20.73</td>\n",
              "      <td>31.12</td>\n",
              "      <td>135.70</td>\n",
              "      <td>1419.0</td>\n",
              "      <td>0.09469</td>\n",
              "      <td>0.11430</td>\n",
              "      <td>0.13670</td>\n",
              "      <td>0.08646</td>\n",
              "      <td>0.1769</td>\n",
              "      <td>0.05674</td>\n",
              "      <td>1.1720</td>\n",
              "      <td>1.6170</td>\n",
              "      <td>7.749</td>\n",
              "      <td>199.70</td>\n",
              "      <td>0.004551</td>\n",
              "      <td>0.01478</td>\n",
              "      <td>0.02143</td>\n",
              "      <td>0.009280</td>\n",
              "      <td>0.01367</td>\n",
              "      <td>0.002299</td>\n",
              "      <td>32.49</td>\n",
              "      <td>47.16</td>\n",
              "      <td>214.00</td>\n",
              "      <td>3432.0</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.2644</td>\n",
              "      <td>0.34420</td>\n",
              "      <td>0.16590</td>\n",
              "      <td>0.2868</td>\n",
              "      <td>0.08218</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51ff972a-0945-4c9a-860e-2f1d06c8ba92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51ff972a-0945-4c9a-860e-2f1d06c8ba92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51ff972a-0945-4c9a-860e-2f1d06c8ba92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  target\n",
              "202        23.29         26.67  ...                  0.08762     0.0\n",
              "130        12.19         13.29  ...                  0.09241     1.0\n",
              "180        27.22         21.87  ...                  0.08082     0.0\n",
              "224        13.27         17.02  ...                  0.07623     1.0\n",
              "329        16.26         21.88  ...                  0.07953     0.0\n",
              "437        14.04         15.98  ...                  0.07234     1.0\n",
              "510        11.74         14.69  ...                  0.09879     1.0\n",
              "499        20.59         21.24  ...                  0.08999     0.0\n",
              "374        13.69         16.07  ...                  0.07701     1.0\n",
              "265        20.73         31.12  ...                  0.08218     0.0\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,1:30] \n",
        "Y  = df.iloc[:,30]"
      ],
      "metadata": {
        "id": "mOAHZOPS_rGf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "vOtXQEX5BBv5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg = 0\n",
        "for i in range(100):\n",
        "  X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3,random_state=i)\n",
        "  model = LogisticRegression()\n",
        "  model.fit(X_train,y_train)\n",
        "  result = model.score(X_test,y_test)\n",
        "  avg = avg + result\n",
        "  print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUyjZ4XDBZ-S",
        "outputId": "b1b9fdcc-0160-488d-85ad-44b0e07862ee"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9532163742690059\n",
            "0.935672514619883\n",
            "0.9239766081871345\n",
            "0.9298245614035088\n",
            "0.9005847953216374\n",
            "0.9649122807017544\n",
            "0.9473684210526315\n",
            "0.9473684210526315\n",
            "0.9415204678362573\n",
            "0.9532163742690059\n",
            "0.9473684210526315\n",
            "0.9181286549707602\n",
            "0.9415204678362573\n",
            "0.9415204678362573\n",
            "0.9532163742690059\n",
            "0.9181286549707602\n",
            "0.9122807017543859\n",
            "0.9122807017543859\n",
            "0.9298245614035088\n",
            "0.935672514619883\n",
            "0.9415204678362573\n",
            "0.9415204678362573\n",
            "0.9181286549707602\n",
            "0.935672514619883\n",
            "0.935672514619883\n",
            "0.9298245614035088\n",
            "0.935672514619883\n",
            "0.9239766081871345\n",
            "0.9473684210526315\n",
            "0.9473684210526315\n",
            "0.9181286549707602\n",
            "0.9298245614035088\n",
            "0.9064327485380117\n",
            "0.9590643274853801\n",
            "0.9649122807017544\n",
            "0.9298245614035088\n",
            "0.9298245614035088\n",
            "0.9473684210526315\n",
            "0.9590643274853801\n",
            "0.9473684210526315\n",
            "0.935672514619883\n",
            "0.9707602339181286\n",
            "0.9649122807017544\n",
            "0.9590643274853801\n",
            "0.9590643274853801\n",
            "0.9473684210526315\n",
            "0.9590643274853801\n",
            "0.9239766081871345\n",
            "0.9532163742690059\n",
            "0.9064327485380117\n",
            "0.9473684210526315\n",
            "0.9473684210526315\n",
            "0.9707602339181286\n",
            "0.9532163742690059\n",
            "0.9649122807017544\n",
            "0.9532163742690059\n",
            "0.9415204678362573\n",
            "0.9122807017543859\n",
            "0.9766081871345029\n",
            "0.9181286549707602\n",
            "0.9707602339181286\n",
            "0.9298245614035088\n",
            "0.9064327485380117\n",
            "0.9766081871345029\n",
            "0.9181286549707602\n",
            "0.9473684210526315\n",
            "0.9239766081871345\n",
            "0.9415204678362573\n",
            "0.935672514619883\n",
            "0.9473684210526315\n",
            "0.935672514619883\n",
            "0.9590643274853801\n",
            "0.9298245614035088\n",
            "0.9473684210526315\n",
            "0.9415204678362573\n",
            "0.9590643274853801\n",
            "0.9181286549707602\n",
            "0.9590643274853801\n",
            "0.9181286549707602\n",
            "0.9415204678362573\n",
            "0.9122807017543859\n",
            "0.9298245614035088\n",
            "0.9122807017543859\n",
            "0.9473684210526315\n",
            "0.9590643274853801\n",
            "0.9239766081871345\n",
            "0.9415204678362573\n",
            "0.9298245614035088\n",
            "0.9590643274853801\n",
            "0.9415204678362573\n",
            "0.935672514619883\n",
            "0.9532163742690059\n",
            "0.9590643274853801\n",
            "0.9590643274853801\n",
            "0.9122807017543859\n",
            "0.9415204678362573\n",
            "0.9181286549707602\n",
            "0.9590643274853801\n",
            "0.9590643274853801\n",
            "0.9532163742690059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg/100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-KA4QJSCpXz",
        "outputId": "b5787811-b8af-416c-87cc-4cbc5099887c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9403508771929815"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross validation"
      ],
      "metadata": {
        "id": "QmI-oLBwERs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold,cross_val_score\n",
        "k = KFold(5)\n",
        "result = cross_val_score(model,X,Y,cv = k)\n",
        "print(result)\n",
        "print()\n",
        "print(np.mean(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWJuwKENC2S3",
        "outputId": "cbe052d1-2cbc-47c6-808c-d5cdee905573"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.90350877 0.92982456 0.97368421 0.93859649 0.9380531 ]\n",
            "\n",
            "0.9367334264865704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper Harameter Tuning"
      ],
      "metadata": {
        "id": "hOZxbba9H7cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "for i in range(2,100):\n",
        "  arr.append(i)\n",
        "print(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZcEe3oiExwm",
        "outputId": "db7265d4-51b1-45e2-f560-6a92a5bbb7ec"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        " \n",
        "for i in arr:\n",
        "  k = KFold(i)\n",
        "  result = cross_val_score(model,X,Y,cv = k)\n",
        "  l.append(np.mean(result))\n",
        "  print(f\"when K = {i}  accuracy = {100*(np.mean(result))} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4e9mocWFFSn",
        "outputId": "abf5be30-1ca9-4951-ea87-8f8452e29812"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when K = 2  accuracy = 92.44625648628613 %\n",
            "when K = 3  accuracy = 93.3203378817414 %\n",
            "when K = 4  accuracy = 93.32463311336551 %\n",
            "when K = 5  accuracy = 93.67334264865704 %\n",
            "when K = 6  accuracy = 93.49757372153788 %\n",
            "when K = 7  accuracy = 93.85727190605239 %\n",
            "when K = 8  accuracy = 93.85758998435055 %\n",
            "when K = 9  accuracy = 94.20469576719577 %\n",
            "when K = 10  accuracy = 93.67794486215537 %\n",
            "when K = 11  accuracy = 94.2033456739339 %\n",
            "when K = 12  accuracy = 94.04181442080379 %\n",
            "when K = 13  accuracy = 93.66970239063262 %\n",
            "when K = 14  accuracy = 94.72560975609755 %\n",
            "when K = 15  accuracy = 94.20104314841156 %\n",
            "when K = 16  accuracy = 93.67559523809523 %\n",
            "when K = 17  accuracy = 94.044248715529 %\n",
            "when K = 18  accuracy = 94.20922939068102 %\n",
            "when K = 19  accuracy = 93.32728372655777 %\n",
            "when K = 20  accuracy = 94.23029556650248 %\n",
            "when K = 21  accuracy = 94.22398589065256 %\n",
            "when K = 22  accuracy = 94.04195804195805 %\n",
            "when K = 23  accuracy = 94.03623188405797 %\n",
            "when K = 24  accuracy = 94.20289855072464 %\n",
            "when K = 25  accuracy = 94.72727272727272 %\n",
            "when K = 26  accuracy = 94.38894438894441 %\n",
            "when K = 27  accuracy = 94.9254449254449 %\n",
            "when K = 28  accuracy = 94.37925170068027 %\n",
            "when K = 29  accuracy = 94.21052631578945 %\n",
            "when K = 30  accuracy = 94.03508771929823 %\n",
            "when K = 31  accuracy = 94.2180720618751 %\n",
            "when K = 32  accuracy = 94.1891339869281 %\n",
            "when K = 33  accuracy = 94.21667656961775 %\n",
            "when K = 34  accuracy = 94.20415224913495 %\n",
            "when K = 35  accuracy = 94.23319327731093 %\n",
            "when K = 36  accuracy = 94.37500000000001 %\n",
            "when K = 37  accuracy = 94.42567567567568 %\n",
            "when K = 38  accuracy = 94.03508771929823 %\n",
            "when K = 39  accuracy = 93.85836385836387 %\n",
            "when K = 40  accuracy = 94.23809523809524 %\n",
            "when K = 41  accuracy = 94.38488340927366 %\n",
            "when K = 42  accuracy = 94.21768707482993 %\n",
            "when K = 43  accuracy = 94.2243802708919 %\n",
            "when K = 44  accuracy = 94.20163170163171 %\n",
            "when K = 45  accuracy = 94.03133903133903 %\n",
            "when K = 46  accuracy = 93.89632107023414 %\n",
            "when K = 47  accuracy = 94.42171303873431 %\n",
            "when K = 48  accuracy = 94.41287878787877 %\n",
            "when K = 49  accuracy = 94.0012368583797 %\n",
            "when K = 50  accuracy = 93.7121212121212 %\n",
            "when K = 51  accuracy = 93.21152703505645 %\n",
            "when K = 52  accuracy = 93.86363636363636 %\n",
            "when K = 53  accuracy = 94.21955403087479 %\n",
            "when K = 54  accuracy = 94.24242424242424 %\n",
            "when K = 55  accuracy = 94.44628099173552 %\n",
            "when K = 56  accuracy = 94.46428571428572 %\n",
            "when K = 57  accuracy = 93.85964912280701 %\n",
            "when K = 58  accuracy = 93.85057471264368 %\n",
            "when K = 59  accuracy = 93.67231638418079 %\n",
            "when K = 60  accuracy = 93.7037037037037 %\n",
            "when K = 61  accuracy = 93.73406193078326 %\n",
            "when K = 62  accuracy = 93.74551971326166 %\n",
            "when K = 63  accuracy = 93.52733686067019 %\n",
            "when K = 64  accuracy = 93.90190972222221 %\n",
            "when K = 65  accuracy = 94.03846153846153 %\n",
            "when K = 66  accuracy = 94.25505050505049 %\n",
            "when K = 67  accuracy = 94.27860696517413 %\n",
            "when K = 68  accuracy = 94.11764705882352 %\n",
            "when K = 69  accuracy = 93.94122383252818 %\n",
            "when K = 70  accuracy = 94.10714285714286 %\n",
            "when K = 71  accuracy = 94.05320813771517 %\n",
            "when K = 72  accuracy = 94.39484126984128 %\n",
            "when K = 73  accuracy = 94.34931506849315 %\n",
            "when K = 74  accuracy = 94.35328185328187 %\n",
            "when K = 75  accuracy = 94.4047619047619 %\n",
            "when K = 76  accuracy = 94.24342105263158 %\n",
            "when K = 77  accuracy = 94.29499072356215 %\n",
            "when K = 78  accuracy = 94.25366300366301 %\n",
            "when K = 79  accuracy = 94.25858951175408 %\n",
            "when K = 80  accuracy = 94.41964285714285 %\n",
            "when K = 81  accuracy = 94.24603174603176 %\n",
            "when K = 82  accuracy = 94.5993031358885 %\n",
            "when K = 83  accuracy = 94.635685599541 %\n",
            "when K = 84  accuracy = 94.5578231292517 %\n",
            "when K = 85  accuracy = 94.59383753501402 %\n",
            "when K = 86  accuracy = 94.76744186046511 %\n",
            "when K = 87  accuracy = 94.74548440065682 %\n",
            "when K = 88  accuracy = 94.58874458874459 %\n",
            "when K = 89  accuracy = 94.46227929373998 %\n",
            "when K = 90  accuracy = 94.62962962962963 %\n",
            "when K = 91  accuracy = 94.6363160648875 %\n",
            "when K = 92  accuracy = 94.61697722567288 %\n",
            "when K = 93  accuracy = 94.77726574500768 %\n",
            "when K = 94  accuracy = 94.73150962512665 %\n",
            "when K = 95  accuracy = 94.03508771929823 %\n",
            "when K = 96  accuracy = 94.02777777777777 %\n",
            "when K = 97  accuracy = 94.0893470790378 %\n",
            "when K = 98  accuracy = 94.01360544217687 %\n",
            "when K = 99  accuracy = 94.006734006734 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.max(l))\n",
        "i = np.argmax(l)\n",
        "print(arr[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shXW1LHrGOB-",
        "outputId": "ad434d72-25c8-4267-e413-a9d43b80b479"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9492544492544491\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stratified K Fold Cross Validation"
      ],
      "metadata": {
        "id": "5A6FkaDYJp2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skfold= StratifiedKFold(n_splits=5)\n",
        "result = cross_val_score(model,X,Y,cv=skfold)\n",
        "print(np.mean(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsUtge36G9yb",
        "outputId": "8777a6ee-4e71-404a-8eda-1b4b36755b47"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9314857941313461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.max(l))\n",
        "i = np.argmax(l)\n",
        "print(arr[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2nRgeOqJK1n",
        "outputId": "a36095c0-137b-4ae9-a4f4-59c7e49f645d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9314857941313461\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leave One Out Cross Validation"
      ],
      "metadata": {
        "id": "mXKi8V-eJuvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "lc = LeaveOneOut()\n",
        "result = cross_val_score(model,X,Y,cv=lc)\n",
        "np.mean(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li2aeE2vJv0V",
        "outputId": "5b3460cd-1e1b-44fc-877d-5cfad0687927"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9437609841827768"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ]
}